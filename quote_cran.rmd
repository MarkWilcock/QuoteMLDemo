---
title: "Quote ML demo - CRAN R with tidyverse implementation"
output: html_document
---

This is a spike to test using ML algorithms against a simulated financial trading dataset

**Use case:**
 
  The bank receives requests for quotes (RFQ) for certain sovereign bonds.  
  The bank has to quote both bid and offer prices but does not know whether counterparty is wanting to buy or sell until after it has quoted.  The purpose of the ML model is to predict whether quote is likely to result in a buy order or sell order 
  i.e.the intent of the counterparty when requesting the quote
  based on some details about the counterparty, the bond and the time of day and the day   
  (since there is some inkling that counterpartoes may have different behaviour at the end of the week or month).
  This is a two class (binary) classifier.
  One attractive feature is that the split of the classes is even - overall the bank expects  
  RFQs to crystallise into approximately 50% buy, 50% sell order
  This is unlike many financial use cases e.g. fraud where the classes are very unbalanced.

```{r, echo=FALSE, message = FALSE, warning=FALSE}
library(readr)
library(dplyr)

library(rpart)
library(rpart.plot)
library(ROCR)
library('rattle')
```

# 1. Ingest

Load the bond quote source data from a CSV file into a dataframe.

```{r}
# read in as a tibble rather than a dataframe
(df <- read_csv(file = "quotedata.csv"))
```


# 2. Feature Engineering

```{r}
df <- df %>%
  select(-TradeKey) %>% 
  mutate(BuySellFlag = ifelse(BuySell == "Buy", 1, 0))

df
```

# 3. Split into training and test datasets

```{r}
set.seed(1234)
# create a new column - each row takes a uniform random variable between 0 and 1
df <- mutate(df, tempval = runif(nrow(df)))
df.train <- filter(df, tempval <= 0.7) %>% select(-tempval)
df.test <- filter(df, tempval > 0.7) %>% select(-tempval)

df.test
```

# 4a. Model and predict - decision tree model.

```{r}
decision.tree.model <-
rpart(BuySellFlag ~ TimeOfDay + IsEndOfWeek + IsEndOfMonth +
        CounterpartyCountry + CounterpartySector + 
        + BondCountry + BondTenor,
        data = df.train,
        method = "class")

fancyRpartPlot(decision.tree.model, cex = 0.6)

```

```{r}
# let's use the decision tree model to predict
decision.tree.prediction <-
  predict(decision.tree.model, df.test, type = "class")

df.test <- mutate(df.test, BuySell.dtree = decision.tree.prediction)

# count of true positives  - can go further to vcalculate  accuracy  etc manually

count.tp <- nrow(filter(df.test, BuySellFlag == 1 & BuySell.dtree == 1))
count.fp <- nrow(filter(df.test, BuySellFlag == 0 & BuySell.dtree == 1))
count.fn <- nrow(filter(df.test, BuySellFlag == 1 & BuySell.dtree == 0))
count.tn <- nrow(filter(df.test, BuySellFlag == 0 & BuySell.dtree == 0))

count.all <- nrow(df.test)
accuracy <- (count.tp + count.tn) / count.all
#precision - what % of items identified were actually in the class
precision = count.tp / (count.tp + count.fp)
#recall aka sensitivity -  what % of items in the class were identified by the classifier
recall = count.tp / (count.tp + count.fn)
specificity = count.tn / (count.tn + count.fp)

paste("Decision tree  model accuracy is", sprintf("%.0f %%", 100 * accuracy))

```

# 4b. Model and predict - logistic regression model.

```{r}
logit.model <-
  glm(BuySellFlag ~ TimeOfDay + IsEndOfWeek + IsEndOfMonth + 
        BondCountry + BondTenor + 
        CounterpartyCountry +  CounterpartySector,
      data= df.train,
      family = binomial(link='logit'))

logit.prediction <- predict (logit.model, df.test, type='response')

df.test <- mutate(df.test, BuySell.logit = ifelse(logit.prediction <= .5, 0, 1))

# count of true positives  - can go further to vcalculate  accuracy  etc manually
count.tp.logit <- nrow(filter(df.test, BuySellFlag == 1 & BuySell.logit == 1))
count.fp.logit <- nrow(filter(df.test, BuySellFlag == 0 & BuySell.logit == 1))
count.fn.logit <- nrow(filter(df.test, BuySellFlag == 1 & BuySell.logit == 0))
count.tn.logit <- nrow(filter(df.test, BuySellFlag == 0 & BuySell.logit == 0))
accuracy.logit <- (count.tp.logit + count.tn.logit) / count.all

paste("Logistic model accuracy is", sprintf("%.0f %%", 100 * accuracy.logit))
```

# 5. Evaluate models

Create the ROC curve for the logistic model.

```{r}
pred <- prediction(logit.prediction, df.test$BuySellFlag)

perf <- performance(pred, measure="tpr", x.measure = "fpr")

options(repr.plot.width = 5, repr.plot.height = 3)
plot(perf, col = rainbow(10), main = "Model performance")
```
